{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os, sys, math, random\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import numpy as np\n",
    "import kornia\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "from tqdm.autonotebook import tqdm\n",
    "from pytorch_pretrained_biggan import BigGAN, convert_to_images, save_as_images\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import random, json\n",
    "\n",
    "from src.notebook_utils import imshow, imgrid, pltshow, draw_tensors\n",
    "from src.face_loss import DlibFaceLoss\n",
    "from src.pytorch_utils import augment\n",
    "from src.palette import random_biggan, load_directory, load_images\n",
    "from src.collage import Collager\n",
    "from src.collage_save import CollageSaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_loss = DlibFaceLoss(filter_index=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from src.gan import Generator\n",
    "mask_generator = Generator(img_size=128, latent_size=100, channels=1).cuda()\n",
    "# https://drive.google.com/file/d/1IhoB6lxbKxL66F0X99ntL-t3-XKnxDPZ/view?usp=sharing\n",
    "model_path = './saved_models/dcgan_gen_128'\n",
    "mask_generator.load_state_dict(torch.load(model_path))\n",
    "mask_generator.eval()\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make or load the palette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_paths = []\n",
    "# for img_dir in ('./datasets/ab_biggan/', './datasets/sci-bio-art/', './datasets/eyes_closed/'):\n",
    "#     img_paths += [ os.path.join(img_dir, n) for n in os.listdir(img_dir) ] \n",
    "\n",
    "img_paths = [\n",
    "    './datasets/ab_biggan/2db513d411406270f1ee_hires.jpeg',\n",
    "    './datasets/ab_biggan/2304b8bce5b78c75893e_hires.jpeg',\n",
    "]\n",
    "    \n",
    "all_palette_imgs_large = load_images(img_paths, 1024)\n",
    "all_palette_imgs = F.interpolate(\n",
    "    all_palette_imgs_large,\n",
    "    size=(img_size, img_size),\n",
    "    mode='bilinear'\n",
    ")\n",
    "# print(len(all_palette_imgs_large))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_steps=600\n",
    "lr=2e-2\n",
    "\n",
    "while True:\n",
    "#     n_refs = random.randint(1, 2)\n",
    "    n_refs = random.choice((1, 2, 3, 4))\n",
    "    indices = random.sample(range(len(all_palette_imgs_large)), n_refs)\n",
    "    patch_per_img = random.randint(8, 28) // n_refs\n",
    "    palette_imgs_large = all_palette_imgs_large[indices]\n",
    "    palette_imgs = all_palette_imgs[indices]\n",
    "    collager = Collager(palette_imgs, mask_generator, img_size, patch_per_img)\n",
    "    \n",
    "    draw_tensors(F.interpolate(palette_imgs, size=(200, 200)))\n",
    "    \n",
    "    frames = []\n",
    "    collage_data = collager.makeRandom(trans_scale=.2)\n",
    "    params = collage_data\n",
    "    Z = collage_data[0]\n",
    "\n",
    "    for x in collage_data:\n",
    "        x.requires_grad_(True)\n",
    "\n",
    "    opt = torch.optim.Adam(params, lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(opt, max_lr=lr, total_steps=n_steps)\n",
    "\n",
    "    pbar = tqdm(total=n_steps)\n",
    "    loss_history = []\n",
    "\n",
    "    for i in range(n_steps):\n",
    "        percent = i / n_steps\n",
    "        pbar.update()        \n",
    "        opt.zero_grad()\n",
    "        fl = torch.zeros(1)\n",
    "        norm_loss = .25 * Z.norm()\n",
    "        img, _ = collager(*collage_data)\n",
    "        aug = augment(img, n=3)\n",
    "        fl = face_loss(((aug+1)*.5)).mean()\n",
    "        loss = fl + norm_loss - .01*img.mean()\n",
    "        loss_history.append(loss.detach().cpu().item())\n",
    "        loss.backward(retain_graph=True)\n",
    "        opt.step()\n",
    "        scheduler.step()\n",
    "        pbar.set_description(f\"fl: {fl.item():.3f}\")\n",
    "        frames.append(\n",
    "            np.array(convert_to_images(img.detach().cpu())[0])\n",
    "        )\n",
    "    # Export results\n",
    "    saver = CollageSaver()\n",
    "    saver.save_palette(palette_imgs)\n",
    "    print(saver.path)\n",
    "    saver.save_video(frames)\n",
    "\n",
    "    draw_tensors(img)\n",
    "\n",
    "    export_collager = Collager(palette_imgs_large, mask_generator, 1024, patch_per_img)\n",
    "    with torch.no_grad():\n",
    "        hires, data = export_collager(*collage_data, return_data=True) \n",
    "        saver.save(hires, data, final=True)\n",
    "\n",
    "    with open(saver.path / 'image_names.txt', 'w') as outfile:\n",
    "        json.dump([img_paths[i] for i in indices], outfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!ls ./results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
